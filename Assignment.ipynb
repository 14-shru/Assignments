{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYrCKkz5C9j3rqOAmxP8Jt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/14-shru/Assignments/blob/main/Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTS**"
      ],
      "metadata": {
        "id": "7jknW5xEMhuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==0.21.3\n",
        "!pip install wget==3.2\n",
        "!pip install gensim==3.6.0\n",
        "!pip install psutil==5.4.8\n",
        "!pip install spacy==2.2.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkQsuJP6Ms2r",
        "outputId": "268f070d-9047-470c-d0e2-fab160053439"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.21.3\n",
            "  Downloading scikit_learn-0.21.3-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.21.6)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.21.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=b7761b42e2ac67e6d02e1a61c0f4b2457e0f7dd8d0bce5e36affd2fbba307912\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim==3.6.0 in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil==5.4.8 in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy==2.2.4\n",
            "  Downloading spacy-2.2.4-cp37-cp37m-manylinux1_x86_64.whl (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 4.0 MB/s \n",
            "\u001b[?25hCollecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 62.7 MB/s \n",
            "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.9.1)\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.0.6)\n",
            "Collecting blis<0.5.0,>=0.4.0\n",
            "  Downloading blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 34.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.21.6)\n",
            "Collecting thinc==7.4.0\n",
            "  Downloading thinc-7.4.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2022.6.15)\n",
            "Installing collected packages: srsly, plac, catalogue, blis, thinc, spacy\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.3\n",
            "    Uninstalling srsly-2.4.3:\n",
            "      Successfully uninstalled srsly-2.4.3\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.7\n",
            "    Uninstalling catalogue-2.0.7:\n",
            "      Successfully uninstalled catalogue-2.0.7\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.8\n",
            "    Uninstalling blis-0.7.8:\n",
            "      Successfully uninstalled blis-0.7.8\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.0.17\n",
            "    Uninstalling thinc-8.0.17:\n",
            "      Successfully uninstalled thinc-8.0.17\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.3.1\n",
            "    Uninstalling spacy-3.3.1:\n",
            "      Successfully uninstalled spacy-3.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.3.0 requires spacy<3.4.0,>=3.3.0.dev0, but you have spacy 2.2.4 which is incompatible.\u001b[0m\n",
            "Successfully installed blis-0.4.1 catalogue-1.0.0 plac-1.1.3 spacy-2.2.4 srsly-1.0.5 thinc-7.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DywLBwsiMPTm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import urllib\n",
        "import re\n",
        "import os\n",
        "import zipfile\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "%matplotlib inline\n",
        "from IPython.core.display import HTML\n",
        "import keras.layers as layers\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape,Embedding,BatchNormalization,Dot,LSTM,Concatenate\n",
        "from tensorflow.keras import Sequential\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify Setup**"
      ],
      "metadata": {
        "id": "0_iqsshrMbZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable/Disable Eager Execution\n",
        "# Reference: https://www.tensorflow.org/guide/eager\n",
        "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
        "# without building graphs\n",
        "\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "#tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "print(\"tensorflow version\", tf.__version__)\n",
        "print(\"keras version\", tf.keras.__version__)\n",
        "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
        "\n",
        "# Get the number of replicas \n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "devices = tf.config.experimental.get_visible_devices()\n",
        "print(\"Devices:\", devices)\n",
        "print(tf.config.experimental.list_logical_devices('GPU'))\n",
        "\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
        "\n",
        "# Better performance with the tf.data API\n",
        "# Reference: https://www.tensorflow.org/guide/data_performance\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNRk-kKNMU10",
        "outputId": "361aaa17-2208-48a2-c602-848d2efec9aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version 2.8.2\n",
            "keras version 2.8.0\n",
            "Eager Execution Enabled: True\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "Number of replicas: 1\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "[]\n",
            "GPU Available:  []\n",
            "All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD AND PRE-PROCESS THE DATASET**"
      ],
      "metadata": {
        "id": "zDcAyKyaOkcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEHA0GptOrcX",
        "outputId": "76c7c33e-44c4-4fe6-e610-b0a663f07a8e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/research/IMDB Dataset.csv')\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "cX8ZSAkKonIr",
        "outputId": "578d9de7-86f0-467c-fb70-3676f86e6ded"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "5  Probably my all-time favorite movie, a story o...  positive\n",
              "6  I sure would like to see a resurrection of a u...  positive\n",
              "7  This show was an amazing, fresh & innovative i...  negative\n",
              "8  Encouraged by the positive comments about this...  negative\n",
              "9  If you like original gut wrenching laughter yo...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-372b81f7-51a3-4aaf-8535-74e025efe4ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-372b81f7-51a3-4aaf-8535-74e025efe4ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-372b81f7-51a3-4aaf-8535-74e025efe4ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-372b81f7-51a3-4aaf-8535-74e025efe4ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_load_datasets(force_download=False):\n",
        "    \n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"IMDB Dataset.csv\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"IMDB Dataset.csv\", \"test\"))\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "rjI5OfHIaii9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_load_datasets_local(force_download=False):\n",
        "  \n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(\"./dataset/\"), \n",
        "                                       \"IMDB Dataset.csv\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(\"./dataset/\"), \n",
        "                                      \"IMDB Dataset.csv\", \"test\"))\n",
        "  \n",
        "    return train_df, test_df\n",
        "\n",
        "    train_df, test_df = download_and_load_datasets()\n",
        "    print(train_df.head())"
      ],
      "metadata": {
        "id": "r5jvGBsgZJ0h"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)"
      ],
      "metadata": {
        "id": "h5ClBx5wbTp5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "metadata": {
        "id": "QM2SAsQhbPFl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train dataset\n",
        "train_reviews=df.review[:40000]\n",
        "train_sentiments=df.sentiment[:40000]\n",
        "#test dataset\n",
        "test_reviews=df.review[40000:]\n",
        "test_sentiments=df.sentiment[40000:]\n",
        "print(train_reviews.shape,train_sentiments.shape)\n",
        "print(test_reviews.shape,test_sentiments.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZf81f48hnnA",
        "outputId": "931f68ae-2311-43f9-db97-a1b6b18b6366"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000,) (40000,)\n",
            "(10000,) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = list(zip(X_train, y_train))\n",
        "random.shuffle(train)\n",
        "X_train, y_train = zip(*train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=SEQ_LENGTH)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=SEQ_LENGTH)"
      ],
      "metadata": {
        "id": "yE-5SuMlrMBZ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Load the word2vec embeddings*"
      ],
      "metadata": {
        "id": "FpucNM3ca9_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wget\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "gn_vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
        "if not os.path.exists(\"GoogleNews-vectors-negative300.bin\"):\n",
        "    if not os.path.exists(\"../Ch2/GoogleNews-vectors-negative300.bin\"):\n",
        "        #Downloading the reqired model\n",
        "        if not os.path.exists(\"../Ch2/GoogleNews-vectors-negative300.bin.gz\"):\n",
        "            if not os.path.exists(\"GoogleNews-vectors-negative300.bin.gz\"):\n",
        "                wget.download(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\")\n",
        "            gn_vec_zip_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "        else:\n",
        "            gn_vec_zip_path = \"../Ch2/GoogleNews-vectors-negative300.bin.gz\"\n",
        "        #Extracting the required model\n",
        "        with gzip.open(gn_vec_zip_path, 'rb') as f_in:\n",
        "            with open(gn_vec_path, 'wb') as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    else:\n",
        "        gn_vec_path = \"../Ch2/\" + gn_vec_path\n",
        "\n",
        "print(f\"Model at {gn_vec_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qm6tXU1a_9M",
        "outputId": "e50b1709-a86f-44fe-e69e-76c46d65d5f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model at GoogleNews-vectors-negative300.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings #This module ignores the various types of warnings generated\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "import psutil #This module helps in retrieving information on running processes and system resource utilization\n",
        "process = psutil.Process(os.getpid())\n",
        "from psutil import virtual_memory\n",
        "mem = virtual_memory()\n",
        "\n",
        "import time #This module is used to calculate the time  "
      ],
      "metadata": {
        "id": "aoiFavXarmor"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define and train the model**"
      ],
      "metadata": {
        "id": "30chTAFbseGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade simple_elmo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY0rLZZWeLoa",
        "outputId": "228fbf00-b90c-4101-e293-4b43b24569cd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting simple_elmo\n",
            "  Downloading simple_elmo-0.9.0-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (3.1.0)\n",
            "Requirement already satisfied: smart-open>1.8.1 in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (5.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from simple_elmo) (1.3.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->simple_elmo) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->simple_elmo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->simple_elmo) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->simple_elmo) (1.15.0)\n",
            "Installing collected packages: simple-elmo\n",
            "Successfully installed simple-elmo-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from simple_elmo import ElmoModel\n",
        "\n",
        "model = ElmoModel()"
      ],
      "metadata": {
        "id": "tju_oRD-ePYi"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/arrival/embeddings/wiki.multi.en.vec -O /tmp/wiki.multi.en.vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc4Ih5ePuYyL",
        "outputId": "3ef78e52-f518-482a-86b5-091329ea1efc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-19 09:11:23--  https://s3.amazonaws.com/arrival/embeddings/wiki.multi.en.vec\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.113.77\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.113.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: unspecified\n",
            "ERROR: Redirection (301) without location.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_vectors(embedding_file_path):\n",
        "    print(\"Loading vectors from\", embedding_file_path)\n",
        "    embeddings = []\n",
        "    word2id = {}"
      ],
      "metadata": {
        "id": "Txk1Wl2Vv87M"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(embedding_file_path, 'r', encoding='utf-8') as f:\n",
        "        next(f)\n",
        "        for i, line in enumerate(f):\n",
        "            word, emb = line.rstrip().split(' ', 1)\n",
        "            emb = np.fromstring(emb, sep=' ')\n",
        "            assert word not in word2id, 'word found twice'\n",
        "            embeddings.append(emb)\n",
        "            word2id[word] = len(word2id)\n",
        "            embeddings = np.vstack(embeddings)\n",
        "            \n",
        "            return embeddings, word2id\n",
        "\n",
        "embeddings_en, embedding_word2id_en = load_vectors(\"/tmp/wiki.multi.en.vec\")\n",
        "            "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "6SgQ7XTXxpQs",
        "outputId": "b479764c-21ec-43c7-d4ca-8f1aaa11787f"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-119-4b0f1b9d6d50>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    return embeddings, word2id\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(target_word2id, embedding_word2id, embeddings, num_rows, num_columns):\n",
        "    embedding_matrix = np.zeros((num_rows, num_columns))\n",
        "    for word, i in target_word2id.items():\n",
        "        if i >= num_rows:\n",
        "            continue\n",
        "        if word in embedding_word2id: \n",
        "            embedding_matrix[i] = embeddings[embedding_word2id[word]]\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "bcoMZd2dwfBQ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2id_en = imdb.get_word_index()\n",
        "word2id_en = {k:(v+INDEX_FROM) for k,v in word2id_en.items()}\n",
        "word2id_en[\"<PAD>\"] = 0\n",
        "word2id_en[\"<START>\"] = START_INDEX\n",
        "word2id_en[\"<UNK>\"] = OOV_INDEX"
      ],
      "metadata": {
        "id": "LOJX-6w2w1Pj"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix_en = create_embedding_matrix(word2id_en, embedding_word2id_en, \n",
        "                                              embeddings_en, VOCABULARY_SIZE+INDEX_FROM-1, EMBEDDING_DIM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "NO7c0gwVwvgI",
        "outputId": "280f11fd-b19c-4b28-bf65-49cd64fa93d2"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-b3ac4c5416c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m embedding_matrix_en = create_embedding_matrix(word2id_en, embedding_word2id_en, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                               embeddings_en, VOCABULARY_SIZE+INDEX_FROM-1, EMBEDDING_DIM)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_word2id_en' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Lambda, Input\n",
        "from keras.layers import Flatten, Concatenate\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "ELMO_EMBEDDING_DIM = 1024\n",
        "\n",
        "def ElmoEmbedding(x):\n",
        "    y = elmo_model(tf.squeeze(x), signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "    return y\n",
        "\n",
        "def create_basic_model():\n",
        "    sequence = Input(shape=(500,))\n",
        "    embedding = Embedding(VOCABULARY_SIZE+INDEX_FROM-1, EMBEDDING_DIM, input_length=SEQ_LENGTH, \n",
        "                              weights=[embedding_matrix_en], trainable=False)(sequence)\n",
        "        \n",
        "    conv = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(embedding)\n",
        "    pool = MaxPooling1D(pool_size=SEQ_LENGTH)(conv)\n",
        "    flat = Flatten()(pool)\n",
        "    dense = Dense(250, activation='relu')(flat)\n",
        "    prediction = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    model = Model(inputs=sequence, outputs=prediction)\n",
        "    optimizer = Adam(lr=0.0001, decay=1e-3)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    #print(model.summary())\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    \n",
        "def create_elmo_model(): \n",
        "    token_sequence = Input(shape=(1,), dtype=\"string\", name=\"elmo_input\")\n",
        "    index_sequence = Input(shape=(SEQ_LENGTH,), name=\"standard_input\")\n",
        "\n",
        "    embedding1 = Lambda(ElmoEmbedding, output_shape=(SEQ_LENGTH, ELMO_EMBEDDING_DIM,))(token_sequence)\n",
        "    embedding2 = Embedding(VOCABULARY_SIZE+INDEX_FROM-1, EMBEDDING_DIM, input_length=SEQ_LENGTH, \n",
        "                          weights=[embedding_matrix_en], trainable=False)(index_sequence)\n",
        "    embedding = Concatenate()([embedding1, embedding2])\n",
        "        \n",
        "    conv = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(embedding)\n",
        "    pool = MaxPooling1D(pool_size=SEQ_LENGTH)(conv)\n",
        "    flat = Flatten()(pool)\n",
        "    dense = Dense(250, activation='relu')(flat)\n",
        "    prediction = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    model = Model(inputs=[index_sequence, token_sequence], outputs=prediction)\n",
        "    optimizer = Adam(lr=0.00001, decay=1e-3)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    #print(model.summary())\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "m16Z-DICugk8"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING**"
      ],
      "metadata": {
        "id": "JpcGD7B4vJLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def train_basic_model(model, X_train, y_train, X_val, y_val, X_test, y_test): \n",
        "    batch_size = 16\n",
        "    earlystop = EarlyStopping(monitor='val_loss', patience=2) \n",
        "    checkpoint = ModelCheckpoint('basic_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
        "              epochs=100, batch_size=batch_size, callbacks=[earlystop, checkpoint])\n",
        "    model.load_weights(filepath='basic_model.hdf5')\n",
        "    scores = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "    return scores[1]*100\n",
        "\n",
        "\n",
        "def train_elmo_model(model, X_train, E_train, y_train, X_val, E_val, y_val, X_test, E_test, y_test): \n",
        "    batch_size = 16\n",
        "    earlystop = EarlyStopping(monitor='val_loss', patience=2)        \n",
        "    checkpoint = ModelCheckpoint('elmo_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "    model.fit([X_train, E_train], y_train, validation_data=([X_val, E_val], y_val), \n",
        "              epochs=100, batch_size=batch_size, callbacks=[earlystop, checkpoint])\n",
        "    model.load_weights(filepath='elmo_model.hdf5')\n",
        "    scores = model.evaluate([X_test, E_test], y_test, batch_size=batch_size)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "    return scores[1]*100"
      ],
      "metadata": {
        "id": "D3znkFzdvIgq"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elmo_accuracies = []\n",
        "basic_accuracies = []\n",
        "\n",
        "test_size = 500\n",
        "validation_size = 200\n",
        "training_size = 200\n",
        "id2word_en = {v:k for k,v in word2id_en.items()}\n",
        "\n",
        "for i in range(10):     \n",
        "    \n",
        "    train = list(zip(X_train, y_train))\n",
        "    test = list(zip(X_test, y_test))\n",
        "    random.shuffle(train)\n",
        "    X_train, y_train = zip(*train)\n",
        "    X_test, y_test = zip(*test)\n",
        "    \n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    \n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "            \n",
        "    train_texts = [\" \".join([id2word_en[idx] for idx in seq]) for seq in X_train[:training_size]]\n",
        "    test_texts = [\" \".join([id2word_en[idx] for idx in seq]) for seq in X_test[:test_size]]\n",
        "    val_texts = [\" \".join([id2word_en[idx] for idx in seq]) for seq in X_test[test_size:test_size+validation_size]]\n",
        "\n",
        "    E_train = np.array(train_texts)\n",
        "    E_test = np.array(test_texts)\n",
        "    E_val = np.array(val_texts)\n",
        "        \n",
        "    model_baseline = create_basic_model()\n",
        "    basic_acc = train_basic_model(model_baseline, X_train[:training_size], y_train[:training_size], \n",
        "                                  X_test[test_size:test_size+validation_size],\n",
        "                                  y_test[test_size:test_size+validation_size], \n",
        "                                  X_test[:test_size], y_test[:test_size])\n",
        "    basic_accuracies.append(basic_acc)\n",
        "\n",
        "    model_elmo = create_elmo_model()\n",
        "    elmo_acc = train_elmo_model(model_elmo, X_train[:training_size], E_train, y_train[:training_size],\n",
        "                                X_test[test_size:test_size+validation_size], \n",
        "                                E_val, y_test[test_size:test_size+validation_size], \n",
        "                                X_test[:test_size], E_test, y_test[:test_size])\n",
        "    elmo_accuracies.append(elmo_acc)\n",
        "        \n",
        "    print(basic_accuracies)\n",
        "    print(elmo_accuracies)\n",
        "    \n",
        "print(np.mean(basic_accuracies))\n",
        "print(np.mean(elmo_accuracies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "w57dwqQgvWmv",
        "outputId": "e77711b6-fabd-4e8b-9be1-46fde4f098af"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-3935ba6f1613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mE_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmodel_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_basic_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     basic_acc = train_basic_model(model_baseline, X_train[:training_size], y_train[:training_size], \n\u001b[1;32m     33\u001b[0m                                   \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-5cf56a161c8a>\u001b[0m in \u001b[0;36mcreate_basic_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     embedding = Embedding(VOCABULARY_SIZE+INDEX_FROM-1, EMBEDDING_DIM, input_length=SEQ_LENGTH, \n\u001b[0;32m---> 21\u001b[0;31m                               weights=[embedding_matrix_en], trainable=False)(sequence)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix_en' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracies = pd.DataFrame({'basic' : basic_accuracies, 'elmo': elmo_accuracies})\n",
        "plt.rcParams['figure.figsize'] = (10,6)\n",
        "accuracies.boxplot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "5GIeI9bV5VQ8",
        "outputId": "29902028-35e4-438e-cbd2-a1203c3aa632"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f46e87bb850>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFlCAYAAACjjD/AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARnUlEQVR4nO3cf8zud13f8dfbnsgUstIfcsta9DDbqEUdbvdKnCy5R0spcVqylQyY2VkCOZmD7IcxsdOldBUTWObYCGA8k2YdmhVD4jyJXbpavJeNOGxBBhStPQNM24GuP4a5IYUV3vvjfGtu79zH/riu9n3ucx6P5M75/vhc1/0+yZVvnue6vueq7g4AAM+ub5geAADgbCTCAAAGiDAAgAEiDABggAgDABggwgAABhyaHuDpuPDCC/vw4cPTY3AAfOlLX8pzn/vc6TGAM4xrC0/FRz/60Qe7+1v2Hj+QEXb48OHcdddd02NwAGxvb2dra2t6DOAM49rCU1FVf7DfcR9HAgAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAgLVEWFVdXVX3VNWJqrpun/PPqaoPLOc/UlWH95z/tqraqaqfWMc8AACnu5UjrKrOSfKeJK9OclmS11fVZXuWvTHJI919SZJ3JnnHnvP/Osl/XnUWAICDYh3vhF2e5ER3f6a7v5rkliTX7FlzTZKbl+0PJrmiqipJquo1ST6b5O41zAIAcCAcWsNzXJTkvl379yd52anWdPdjVfXFJBdU1aNJfjLJK5P8mR9FVtXRJEeTZGNjI9vb22sYnTPdzs6O1wqwdq4trMM6ImwVNyR5Z3fvLG+MnVJ3H0tyLEk2Nzd7a2vrGR+Og297ezteK8C6ubawDuuIsAeSvGjX/sXLsf3W3F9Vh5Kcm+ShnHzH7Nqq+pdJnp/k61X1aHe/ew1zAQCcttYRYXcmubSqXpyTsfW6JG/Ys+Z4kiNJfivJtUk+1N2d5K8/vqCqbkiyI8AAgLPByhG23OP1liS3JTknyU3dfXdV3Zjkru4+nuR9Sd5fVSeSPJyToQYAcNZayz1h3X1rklv3HLt+1/ajSV77BM9xwzpmAQA4CHxjPgDAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBgLRFWVVdX1T1VdaKqrtvn/HOq6gPL+Y9U1eHl+Cur6qNV9cnlz1esYx4AgNPdyhFWVeckeU+SVye5LMnrq+qyPcvemOSR7r4kyTuTvGM5/mCSH+7u701yJMn7V50HAOAgWMc7YZcnOdHdn+nurya5Jck1e9Zck+TmZfuDSa6oquru3+nu/70cvzvJN1XVc9YwEwDAae3QGp7joiT37dq/P8nLTrWmux+rqi8muSAn3wl73N9O8rHu/sp+v6SqjiY5miQbGxvZ3t5ew+ic6XZ2drxWgLVzbWEd1hFhK6uql+TkR5RXnWpNdx9LcixJNjc3e2tr69kZjgNte3s7XivAurm2sA7r+DjygSQv2rV/8XJs3zVVdSjJuUkeWvYvTvKrSf5ed/+vNcwDAHDaW0eE3Znk0qp6cVV9Y5LXJTm+Z83xnLzxPkmuTfKh7u6qen6SX09yXXd/eA2zAAAcCCtHWHc/luQtSW5L8rtJfqW7766qG6vqR5Zl70tyQVWdSPLjSR7/Gou3JLkkyfVV9fHl5wWrzgQAcLpbyz1h3X1rklv3HLt+1/ajSV67z+PeluRt65gBAOAg8Y35AAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwIC1RFhVXV1V91TViaq6bp/zz6mqDyznP1JVh3ed+2fL8Xuq6lXrmAcA4HS3coRV1TlJ3pPk1UkuS/L6qrpsz7I3Jnmkuy9J8s4k71gee1mS1yV5SZKrk7x3eT4AgDPaOt4JuzzJie7+THd/NcktSa7Zs+aaJDcv2x9MckVV1XL8lu7+Snd/NsmJ5fkAAM5o64iwi5Lct2v//uXYvmu6+7EkX0xywZN8LADAGefQ9ABPVlUdTXI0STY2NrK9vT07EAfCzs6O1wqwdq4trMM6IuyBJC/atX/xcmy/NfdX1aEk5yZ56Ek+NknS3ceSHEuSzc3N3traWsPonOm2t7fjtQKsm2sL67COjyPvTHJpVb24qr4xJ2+0P75nzfEkR5bta5N8qLt7Of665X9PvjjJpUl+ew0zAQCc1lZ+J6y7H6uqtyS5Lck5SW7q7rur6sYkd3X38STvS/L+qjqR5OGcDLUs634lyaeTPJbkzd39tVVnAgA43a3lnrDuvjXJrXuOXb9r+9Ekrz3FY382yc+uYw4AgIPCN+YDAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMCAlSKsqs6vqtur6t7lz/NOse7IsubeqjqyHPvmqvr1qvq9qrq7qt6+yiwAAAfJqu+EXZfkju6+NMkdy/6fUlXnJ3lrkpcluTzJW3fF2r/q7u9K8v1JfrCqXr3iPAAAB8KqEXZNkpuX7ZuTvGafNa9Kcnt3P9zdjyS5PcnV3f3l7v7NJOnuryb5WJKLV5wHAOBAOLTi4ze6+/PL9heSbOyz5qIk9+3av3859ieq6vlJfjjJvz3VL6qqo0mOJsnGxka2t7ef/tScNXZ2drxWgLVzbWEdnjDCquo3knzrPqd+evdOd3dV9VMdoKoOJfmPSd7V3Z851bruPpbkWJJsbm721tbWU/1VnIW2t7fjtQKsm2sL6/CEEdbdV57qXFX9YVW9sLs/X1UvTPJH+yx7IMnWrv2Lk2zv2j+W5N7u/jdPamIAgDPAqveEHU9yZNk+kuTX9llzW5Krquq85Yb8q5Zjqaq3JTk3yT9ZcQ4AgANl1Qh7e5JXVtW9Sa5c9lNVm1X1i0nS3Q8n+Zkkdy4/N3b3w1V1cU5+pHlZko9V1cer6k0rzgMAcCCsdGN+dz+U5Ip9jt+V5E279m9KctOeNfcnqVV+PwDAQeUb8wEABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABK0VYVZ1fVbdX1b3Ln+edYt2RZc29VXVkn/PHq+pTq8wCAHCQrPpO2HVJ7ujuS5Pcsez/KVV1fpK3JnlZksuTvHV3rFXV30qys+IcAAAHyqoRdk2Sm5ftm5O8Zp81r0pye3c/3N2PJLk9ydVJUlXPS/LjSd624hwAAAfKoRUfv9Hdn1+2v5BkY581FyW5b9f+/cuxJPmZJD+X5MtP9Iuq6miSo0mysbGR7e3tpzkyZ5OdnR2vFWDtXFtYhyeMsKr6jSTfus+pn969091dVf1kf3FVvTTJd3T3P62qw0+0vruPJTmWJJubm721tfVkfxVnse3t7XitAOvm2sI6PGGEdfeVpzpXVX9YVS/s7s9X1QuT/NE+yx5IsrVr/+Ik20l+IMlmVX1umeMFVbXd3VsBADjDrXpP2PEkj/9vxyNJfm2fNbcluaqqzltuyL8qyW3d/fPd/Re6+3CSlyf5fQEGAJwtVo2wtyd5ZVXdm+TKZT9VtVlVv5gk3f1wTt77defyc+NyDADgrLXSjfnd/VCSK/Y5fleSN+3avynJTX/G83wuyfesMgsAwEHiG/MBAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGBAdff0DE9ZVf2fJH8wPQcHwoVJHpweAjjjuLbwVHx7d3/L3oMHMsLgyaqqu7p7c3oO4Mzi2sI6+DgSAGCACAMAGCDCONMdmx4AOCO5trAy94QBAAzwThgAwAARxoFSVYer6lMrPsePVNV165oJOHNV1eeq6sLpOTgzHZoeAJ5t3X08yfHpOQA4u3knjIPoUFX9clX9blV9sKq+uaqur6o7q+pTVXWsqipJquofVdWnq+oTVXXLcuzvV9W7l+2NqvrVqvqfy89fm/yLAXOq6ker6rer6uNV9QtVdc6uc4er6veq6t9X1e8v16Arq+rDVXVvVV2+rDu/qv7Tcs35H1X1fXN/I053IoyD6DuTvLe7vzvJHyf5h0ne3d1/tbu/J8k3Jfmby9rrknx/d39fkn+wz3O9K8l/7e6/lOQvJ7n7GZ8eOO1U1Xcn+TtJfrC7X5rka0n+7p5llyT5uSTftfy8IcnLk/xEkp9a1vyLJL+zXHN+Ksl/eOan56ASYRxE93X3h5ftX8rJi+DfqKqPVNUnk7wiyUuW859I8stV9aNJHtvnuV6R5OeTpLu/1t1ffGZHB05TVyT5K0nurKqPL/t/cc+az3b3J7v76zn5D7Y7+uRXDHwyyeFlzcuTvD9JuvtDSS6oqj//LMzPASTCOIj2fq9KJ3lvkmu7+3uT/Lskf24590NJ3pOT73LdWVXugwT2U0lu7u6XLj/f2d037FnzlV3bX9+1//W4x5qnQYRxEH1bVf3Asv2GJP992X6wqp6X5NokqapvSPKi7v7NJD+Z5Nwkz9vzXHck+bFl/TlVde4zPTxwWrojybVV9YLkT+7t+van8Tz/LcvHmFW1leTB7v7jtU3JGUW5cxDdk+TNVXVTkk/n5MeJ5yX5VJIvJLlzWXdOkl9awqqSvKu7/+9yz/7j/nGSY1X1xpy8B+THkvzWs/K3AE4b3f3pqvrnSf7L8g+4/5fkzU/jqW5IclNVfSLJl5McWd+UnGl8Yz4AwAAfRwIADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMOD/A7cklOBEYbk6AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair plot\n",
        "plt.scatter(np.zeros(len(basic_accuracies)), basic_accuracies)\n",
        "plt.scatter(np.ones(len(elmo_accuracies)), elmo_accuracies)\n",
        "\n",
        "for i in range(len(basic_accuracies)):\n",
        "    plt.plot( [0,1], [basic_accuracies[i], elmo_accuracies[i]], c='k')\n",
        "\n",
        "plt.xticks([0,1], ['basic', 'elmo'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "NgjRdlrU5Xqu",
        "outputId": "680be81c-2aab-45a5-dfba-66efdb9b160e"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}